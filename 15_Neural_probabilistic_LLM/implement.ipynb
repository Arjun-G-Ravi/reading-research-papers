{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "embedding_dims = 10 # how many dimensional vector should represent each word in the vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "df = ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', '!', '!', '!', 'name', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    data = sentence\n",
    "    split_terms = [',', '.', '!', '?', '(', ')', '&', '$', '+', '-', '/', '*', ';', ':']\n",
    "    for split_term in split_terms:\n",
    "        if split_term in sentence:\n",
    "            data = data.replace(split_term, f' {split_term} ')\n",
    "    data = data.split()\n",
    "    return data\n",
    "\n",
    "tokenize('what is your !! ! name ?    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = set()\n",
    "X = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'\n",
    "    data = data.lower().replace('\\\\n', '')\n",
    "    vocab_list.update(tokenize(data))\n",
    "    X.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list.add('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {v:i for v,i in zip(vocab_list, range(0, len(vocab_list)+1))}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neural': 0,\n",
       " 'networks': 1,\n",
       " 'type': 2,\n",
       " 'main': 3,\n",
       " 'typically': 4,\n",
       " 'by': 5,\n",
       " 'system': 6,\n",
       " 'where': 7,\n",
       " 'brain': 8,\n",
       " 'inspired': 9,\n",
       " 'over': 10,\n",
       " 'like': 11,\n",
       " 'vision': 12,\n",
       " 'learn': 13,\n",
       " 'algorithm': 14,\n",
       " 'task': 15,\n",
       " 'way': 16,\n",
       " 'focuses': 17,\n",
       " 'learns': 18,\n",
       " 'examples': 19,\n",
       " 'around': 20,\n",
       " 'translation': 21,\n",
       " 'aims': 22,\n",
       " 'an': 23,\n",
       " 'while': 24,\n",
       " ',': 25,\n",
       " 'complex': 26,\n",
       " 'without': 27,\n",
       " 'layers': 28,\n",
       " 'interconnected': 29,\n",
       " '?': 30,\n",
       " 'nodes': 31,\n",
       " ':': 32,\n",
       " 'labeled': 33,\n",
       " 'various': 34,\n",
       " 'uses': 35,\n",
       " 'given': 36,\n",
       " '.': 37,\n",
       " 'simulate': 38,\n",
       " 'development': 39,\n",
       " '-': 40,\n",
       " 'artificial': 41,\n",
       " 'two': 42,\n",
       " 'such': 43,\n",
       " 'computers': 44,\n",
       " 'this': 45,\n",
       " '<UNK>': 46,\n",
       " 'human': 47,\n",
       " 'in': 48,\n",
       " 'or': 49,\n",
       " 'that': 50,\n",
       " 'relationships': 51,\n",
       " 'make': 52,\n",
       " 'patterns': 53,\n",
       " 'penalty': 54,\n",
       " 'learning': 55,\n",
       " 'on': 56,\n",
       " 'language': 57,\n",
       " 'generate': 58,\n",
       " 'works': 59,\n",
       " 'form': 60,\n",
       " 'transmit': 61,\n",
       " 'making': 62,\n",
       " 'consists': 63,\n",
       " 'speech': 64,\n",
       " 'based': 65,\n",
       " 'allows': 66,\n",
       " 'to': 67,\n",
       " 'perception': 68,\n",
       " 'what': 69,\n",
       " 'systems': 70,\n",
       " 'being': 71,\n",
       " 'perform': 72,\n",
       " 'processing': 73,\n",
       " 'understand': 74,\n",
       " 'its': 75,\n",
       " 'would': 76,\n",
       " 'reward': 77,\n",
       " 'network': 78,\n",
       " 'tasks': 79,\n",
       " 'world': 80,\n",
       " 'machine': 81,\n",
       " 'decisions': 82,\n",
       " 'reinforcement': 83,\n",
       " 'us': 84,\n",
       " 'refers': 85,\n",
       " 'answer': 86,\n",
       " 'information': 87,\n",
       " 'intelligence': 88,\n",
       " 'computer': 89,\n",
       " 'process': 90,\n",
       " 'takes': 91,\n",
       " 'have': 92,\n",
       " 'natural': 93,\n",
       " 'time': 94,\n",
       " 'recognition': 95,\n",
       " 'environment': 96,\n",
       " 'general': 97,\n",
       " 'is': 98,\n",
       " 'improve': 99,\n",
       " 'as': 100,\n",
       " 'a': 101,\n",
       " 'structure': 102,\n",
       " 'many': 103,\n",
       " 'categories': 104,\n",
       " 'narrow': 105,\n",
       " 'ai': 106,\n",
       " 'feedback': 107,\n",
       " 'subset': 108,\n",
       " 'visual': 109,\n",
       " 'function': 110,\n",
       " 'designed': 111,\n",
       " 'unsupervised': 112,\n",
       " 'and': 113,\n",
       " 'maximize': 114,\n",
       " 'it': 115,\n",
       " 'are': 116,\n",
       " 'receives': 117,\n",
       " 'from': 118,\n",
       " 'of': 119,\n",
       " 'predictions': 120,\n",
       " 'decision': 121,\n",
       " 'the': 122,\n",
       " 'algorithms': 123,\n",
       " 'take': 124,\n",
       " 'enabling': 125,\n",
       " 'can': 126,\n",
       " 'specific': 127,\n",
       " 'with': 128,\n",
       " 'interpret': 129,\n",
       " 'analyze': 130,\n",
       " 'question': 131,\n",
       " 'data': 132,\n",
       " 'using': 133,\n",
       " 'deep': 134,\n",
       " 'actions': 135,\n",
       " 'ability': 136,\n",
       " 'signal': 137,\n",
       " 'computing': 138,\n",
       " 'require': 139,\n",
       " 'neurons': 140}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.randn(len(vocab),embedding_dims)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8063, -0.6507,  0.3987,  1.6612,  0.7751, -0.0549,  1.3940,  1.7015,\n",
       "          0.3626, -0.5787],\n",
       "        [-0.5516,  0.9090, -1.4153, -0.1322, -0.0741, -2.0019, -0.3743,  0.4923,\n",
       "         -0.2098,  1.6077],\n",
       "        [-1.7951,  0.0110, -1.4094, -0.4328,  0.2410,  0.3412, -0.7195, -0.6139,\n",
       "         -0.1315, -0.0925]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1914, -2.0334,  1.6065,  0.2783,  0.8104,  1.7177,  0.6526, -0.9009,\n",
       "         1.5135, -0.1461])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding(word, vocab=vocab, embedding_matrix=embedding_matrix):\n",
    "    if word not in vocab:\n",
    "        word = '<UNK>'\n",
    "    embedding = embedding_matrix[vocab[word]]\n",
    "    return embedding\n",
    "\n",
    "get_word_embedding('as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=n, num_hidden_layer=1024, vocab = vocab, dim_embedding=10):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        vocab_len = len(vocab)\n",
    "        self.n = n\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.embedding = nn.Embedding(vocab_len, dim_embedding).to(device)\n",
    "\n",
    "        self.hidden_layer = nn.Linear((n-1)*dim_embedding, num_hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(num_hidden_layer, vocab_len)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x will be the indices of embedding representing the input words\n",
    "        x_embeddings = self.embedding(x).view(-1,(self.n-1)*self.dim_embedding).to(device)\n",
    "        out = self.hidden_layer(x_embeddings)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        print(out.shape)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def generate(self, x):\n",
    "        logits = self.forward(x)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prob, predicted_token_index = torch.max(probs, dim=1)\n",
    "\n",
    "        return predicted_token_index\n",
    "\n",
    "model = NeuralNetwork(n=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'.lower()\n",
    "    tokenized_data = tokenize(data)\n",
    "    for i in range(len(tokenized_data)-n):\n",
    "        # print(i)\n",
    "        data_i = tokenized_data[i:i+n]\n",
    "        dataset.append([vocab[i] if i in vocab else vocab['<UNK>'] for i in data_i])\n",
    "    # print()\n",
    "\n",
    "dataset_np = np.array(dataset)\n",
    "dataset_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.x = dataset[:,[i for i in range(n-1)]]\n",
    "        self.y = dataset[:,-1]\n",
    "        self.m, self.n = self.x.shape\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.m\n",
    "    \n",
    "dataset = QuestionAnswerDataset(dataset=dataset_np)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCategory = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 141])\n",
      "4.981202125549316\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "4.739145755767822\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "4.494852542877197\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "4.276157379150391\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "4.159060001373291\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "3.986175537109375\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "3.8269906044006348\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "3.7358720302581787\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "3.6913106441497803\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "3.557495594024658\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n",
      "torch.Size([256, 141])\n",
      "torch.Size([163, 141])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (input, label) in enumerate(dataloader):\n",
    "        x = input.to(device)\n",
    "        y = label.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = lossCategory(y_pred, y)\n",
    "        if epoch%10==0 and i==0: \n",
    "            # print(epoch)\n",
    "            print(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 69,  98, 101,  30], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'What is a ?'\n",
    "tokenized_text = tokenize(text.lower())\n",
    "embedding_indices = torch.tensor(np.array([vocab[word] for word in tokenized_text])).to(device)\n",
    "embedding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 69,  98, 101,  30], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 141])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([101,  86], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(embedding_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_rev = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_rev[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(141, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# normalisation, standardise, proper init, weight decay, hyperparameter tunign, diff optimiser test, inference, earlyy stopping\n",
    "# add direct connections, see if it is useful\n",
    "# plot unigram, bi, tri, etc perplexity score, word error rate, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
