{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 500\n",
    "n = 25\n",
    "embedding_dims = 10 # how many dimensional vector should represent each word in the vocabulory\n",
    "num_epochs = 100\n",
    "lr = 0.1\n",
    "lr_coeff = 0.1\n",
    "max_words = 30\n",
    "train_data = 10000\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (37635, 2)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "df = ds['train'][:train_data]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', '!', '!', '!', 'name', '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    data = sentence\n",
    "    split_terms = [',', '.', '!', '?', '(', ')', '&', '$', '+', '-', '/', '*', ';', ':']\n",
    "    for split_term in split_terms:\n",
    "        if split_term in sentence:\n",
    "            data = data.replace(split_term, f' {split_term} ')\n",
    "    data = data.split()\n",
    "    return data\n",
    "\n",
    "tokenize('what is your !! ! name ?    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = set()\n",
    "X = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'\n",
    "    data = data.lower().replace('\\\\n', '')\n",
    "    vocab_list.update(tokenize(data))\n",
    "    X.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23447"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.add('<PAD>')\n",
    "vocab_list.add('<start>')\n",
    "vocab_list.add('<end>')\n",
    "vocab = {v:i for v,i in zip(vocab_list, range(1, len(vocab_list)+1))}\n",
    "vocab['<UNK>'] = 0\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23447, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.randn(len(vocab),embedding_dims)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1711,  1.0565, -1.7252, -1.8323, -0.7994,  0.2763, -0.2164, -1.1071,\n",
       "        -0.5422, -0.9592])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding(word, vocab=vocab, embedding_matrix=embedding_matrix):\n",
    "    if word not in vocab:\n",
    "        word = '<UNK>'\n",
    "    embedding = embedding_matrix[vocab[word]]\n",
    "    return embedding\n",
    "\n",
    "get_word_embedding('as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=n, num_hidden_layer=1024, vocab = vocab, dim_embedding=10):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.rev_vocab = {v:k for k,v in vocab.items()}\n",
    "        vocab_len = len(vocab)\n",
    "        self.n = n\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.embedding = nn.Embedding(vocab_len, dim_embedding).to(device)\n",
    "\n",
    "        self.hidden_layer = nn.Linear((n-1)*dim_embedding, num_hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(num_hidden_layer, vocab_len)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x will be the indices of embedding representing the input words\n",
    "        x = torch.tensor(x).to(device)\n",
    "        # x = x[-(n-1):]\n",
    "        # print(x.shape)\n",
    "        x_embeddings = self.embedding(x).view(-1,(self.n-1)*self.dim_embedding).to(device)\n",
    "        out = self.hidden_layer(x_embeddings)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def generate(self, x):\n",
    "        x = torch.tensor(x).to(device)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # assert x.shape == 0 # fix shape here, and write a loop to do autoregressive text gen\n",
    "        x = x[-(n-1):]\n",
    "        # assert len(x) == self.n - 1\n",
    "        logits = self.forward(x)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prob, predicted_token_index = torch.max(probs, dim=1)\n",
    "        # print(self.embedding(x).shape)  # Shape before reshaping\n",
    "        # print((self.n-1)*self.dim_embedding)  # Expected shape size\n",
    "\n",
    "        return predicted_token_index\n",
    "\n",
    "model = NeuralNetwork(n=n).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10428, 10428, 10428, 10428, 10428, 10428, 10428, 10428, 12159],\n",
       " [10428, 10428, 10428, 10428, 10428, 10428, 10428, 12159, 8808],\n",
       " [10428, 10428, 10428, 10428, 10428, 10428, 12159, 8808, 786]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sentece_to_n_grams(tokenized_sentence, n, vocab):\n",
    "    res = []\n",
    "    data_init = ['<PAD>' for i in range(n-1)]\n",
    "    for word in tokenized_sentence:\n",
    "        data_init.append(word)\n",
    "        sentence = data_init[-n:]\n",
    "        # print(sentence)\n",
    "        res.append([vocab[word] if word in vocab else vocab['<UNK>'] for word in sentence])\n",
    "    return res\n",
    "\n",
    "split_sentece_to_n_grams(['what', 'is', 'your'], 9 ,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'<start> Question: {x} Answer: {y} <end>'.lower()\n",
    "    tokenized_data = tokenize(data)\n",
    "    dataset.extend(split_sentece_to_n_grams(tokenized_data, n, vocab))\n",
    "\n",
    "dataset_np = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.x = dataset[:,[i for i in range(n-1)]]\n",
    "        self.y = dataset[:,-1]\n",
    "        self.m, self.n = self.x.shape\n",
    "        self.standardize()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.m\n",
    "\n",
    "    def standardize(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.dataset = scaler.fit_transform(self.dataset) \n",
    "dataset = QuestionAnswerDataset(dataset=dataset_np)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "lossCategory = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 10.081502914428711\n",
      "Epoch 10 Loss: 4.284249782562256\n",
      "Epoch 20 Loss: 3.6533846855163574\n",
      "Epoch 30 Loss: 2.7321884632110596\n",
      "Epoch 40 Loss: 2.239819288253784\n",
      "Epoch 50 Loss: 1.6325013637542725\n",
      "Epoch 60 Loss: 1.5693230628967285\n",
      "Epoch 70 Loss: 1.5376567840576172\n",
      "Epoch 80 Loss: 1.6682907342910767\n",
      "Epoch 90 Loss: 1.5232880115509033\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inp, label) in enumerate(dataloader):\n",
    "        x = inp.to(device)\n",
    "        y = label.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = lossCategory(y_pred, y)\n",
    "        if epoch%10==0 and i==0: \n",
    "            print(f'Epoch {epoch} Loss: {loss.item()}')\n",
    "        lr = lr/(1+lr_coeff*epoch)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad() # The loss has to go below .5 for the model to be good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_rev = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<start> Question: what is deep learning?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> question: what is deep learning? answer : an electrophile is the theory of an issue <UNK> <UNK> ( <UNK> <UNK> <UNK> <UNK> <UNK> function <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> anagrams <UNK> <UNK> <UNK> <UNK> <UNK> "
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenize(text.lower())\n",
    "embedding_indices = np.array(split_sentece_to_n_grams(tokenized_text, n, vocab))\n",
    "gen_word = ''\n",
    "data_stream = list(embedding_indices[-1])\n",
    "words_generated = 0\n",
    "print(text.lower(), end = ' ')\n",
    "while gen_word != vocab['<end>'] and words_generated <= max_words:\n",
    "    data_stream = data_stream[-(n-1):]\n",
    "    gen_word = model.generate(data_stream)\n",
    "    words_generated += 1\n",
    "    data_stream.append(gen_word.item())\n",
    "    \n",
    "    print(vocab_rev[gen_word.item()], end= ' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# proper init, weight decay, hyperparameter tunign, diff optimiser test\n",
    "# add direct connections, see if it is useful\n",
    "# plot unigram, bi, tri, etc perplexity score, word error rate, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
