{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulory and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "embedding_dims = 10 # how many dimensional vector should represent each word in the vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "df = ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', '!', '!', '!', 'name', '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    data = sentence\n",
    "    split_terms = [',', '.', '!', '?', '(', ')', '&', '$', '+', '-', '/', '*', ';', ':']\n",
    "    for split_term in split_terms:\n",
    "        if split_term in sentence:\n",
    "            data = data.replace(split_term, f' {split_term} ')\n",
    "    data = data.split()\n",
    "    return data\n",
    "\n",
    "tokenize('what is your !! ! name ?    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = set()\n",
    "X = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'\n",
    "    data = data.lower().replace('\\\\n', '')\n",
    "    vocab_list.update(tokenize(data))\n",
    "    X.append(data)\n",
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list.add('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {v:i for v,i in zip(vocab_list, range(1, len(vocab_list)+1))}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recognition': 1,\n",
       " 'works': 2,\n",
       " 'decisions': 3,\n",
       " 'focuses': 4,\n",
       " '<UNK>': 5,\n",
       " 'consists': 6,\n",
       " 'take': 7,\n",
       " 'improve': 8,\n",
       " 'data': 9,\n",
       " 'is': 10,\n",
       " 'perform': 11,\n",
       " 'by': 12,\n",
       " 'ai': 13,\n",
       " 'intelligence': 14,\n",
       " 'penalty': 15,\n",
       " 'relationships': 16,\n",
       " 'process': 17,\n",
       " 'can': 18,\n",
       " 'typically': 19,\n",
       " 'algorithms': 20,\n",
       " 'many': 21,\n",
       " '-': 22,\n",
       " 'are': 23,\n",
       " 'inspired': 24,\n",
       " 'learning': 25,\n",
       " 'it': 26,\n",
       " 'answer': 27,\n",
       " 'given': 28,\n",
       " 'perception': 29,\n",
       " 'and': 30,\n",
       " 'being': 31,\n",
       " 'type': 32,\n",
       " 'environment': 33,\n",
       " 'systems': 34,\n",
       " 'receives': 35,\n",
       " 'allows': 36,\n",
       " 'generate': 37,\n",
       " 'that': 38,\n",
       " 'over': 39,\n",
       " 'designed': 40,\n",
       " 'vision': 41,\n",
       " 'computer': 42,\n",
       " 'natural': 43,\n",
       " 'feedback': 44,\n",
       " 'would': 45,\n",
       " 'takes': 46,\n",
       " 'have': 47,\n",
       " 'around': 48,\n",
       " 'information': 49,\n",
       " 'signal': 50,\n",
       " 'or': 51,\n",
       " 'system': 52,\n",
       " 'nodes': 53,\n",
       " 'function': 54,\n",
       " 'various': 55,\n",
       " 'form': 56,\n",
       " 'with': 57,\n",
       " 'artificial': 58,\n",
       " 'without': 59,\n",
       " 'brain': 60,\n",
       " 'understand': 61,\n",
       " 'two': 62,\n",
       " 'patterns': 63,\n",
       " 'neurons': 64,\n",
       " '?': 65,\n",
       " 'examples': 66,\n",
       " 'tasks': 67,\n",
       " 'reward': 68,\n",
       " 'complex': 69,\n",
       " 'structure': 70,\n",
       " 'aims': 71,\n",
       " 'in': 72,\n",
       " 'where': 73,\n",
       " 'transmit': 74,\n",
       " 'language': 75,\n",
       " 'narrow': 76,\n",
       " 'us': 77,\n",
       " 'reinforcement': 78,\n",
       " 'layers': 79,\n",
       " 'algorithm': 80,\n",
       " 'uses': 81,\n",
       " 'enabling': 82,\n",
       " ',': 83,\n",
       " 'human': 84,\n",
       " 'learn': 85,\n",
       " 'labeled': 86,\n",
       " 'networks': 87,\n",
       " 'network': 88,\n",
       " 'what': 89,\n",
       " 'like': 90,\n",
       " 'machine': 91,\n",
       " '.': 92,\n",
       " 'analyze': 93,\n",
       " 'to': 94,\n",
       " 'such': 95,\n",
       " 'computers': 96,\n",
       " 'its': 97,\n",
       " 'speech': 98,\n",
       " 'world': 99,\n",
       " 'as': 100,\n",
       " 'require': 101,\n",
       " 'make': 102,\n",
       " ':': 103,\n",
       " 'making': 104,\n",
       " 'translation': 105,\n",
       " 'deep': 106,\n",
       " 'visual': 107,\n",
       " 'time': 108,\n",
       " 'a': 109,\n",
       " 'simulate': 110,\n",
       " 'way': 111,\n",
       " 'while': 112,\n",
       " 'ability': 113,\n",
       " 'processing': 114,\n",
       " 'on': 115,\n",
       " 'this': 116,\n",
       " 'development': 117,\n",
       " 'computing': 118,\n",
       " 'refers': 119,\n",
       " 'task': 120,\n",
       " 'actions': 121,\n",
       " 'maximize': 122,\n",
       " 'neural': 123,\n",
       " 'unsupervised': 124,\n",
       " 'decision': 125,\n",
       " 'categories': 126,\n",
       " 'predictions': 127,\n",
       " 'interconnected': 128,\n",
       " 'the': 129,\n",
       " 'interpret': 130,\n",
       " 'an': 131,\n",
       " 'of': 132,\n",
       " 'main': 133,\n",
       " 'general': 134,\n",
       " 'question': 135,\n",
       " 'using': 136,\n",
       " 'specific': 137,\n",
       " 'subset': 138,\n",
       " 'from': 139,\n",
       " 'learns': 140,\n",
       " 'based': 141}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.randn(len(vocab),embedding_dims)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4681, -0.6751,  1.4149,  0.6815,  0.1955,  1.8689,  0.1731,  1.3575,\n",
       "        -0.0200,  0.0611])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding(word, vocab=vocab, embedding_matrix=embedding_matrix):\n",
    "    if word not in vocab:\n",
    "        word = '<UNK>'\n",
    "    embedding = embedding_matrix[vocab[word]]\n",
    "    return embedding\n",
    "\n",
    "get_word_embedding('as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=n, dim_embedding=embedding_dims, vocab_length=len(vocab), num_hidden_layer=100):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(dim_embedding, num_hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(num_hidden_layer, vocab_length)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # shape of x: (n, dim_embedding) -> (3, 10)\n",
    "        out = self.hidden_layer(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 141])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_x = torch.randn((3,10))\n",
    "# model(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCategory = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
