{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "embedding_dims = 10 # how many dimensional vector should represent each word in the vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "df = ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', '!', '!', '!', 'name', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    data = sentence\n",
    "    split_terms = [',', '.', '!', '?', '(', ')', '&', '$', '+', '-', '/', '*', ';', ':']\n",
    "    for split_term in split_terms:\n",
    "        if split_term in sentence:\n",
    "            data = data.replace(split_term, f' {split_term} ')\n",
    "    data = data.split()\n",
    "    return data\n",
    "\n",
    "tokenize('what is your !! ! name ?    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = set()\n",
    "X = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'\n",
    "    data = data.lower().replace('\\\\n', '')\n",
    "    vocab_list.update(tokenize(data))\n",
    "    X.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list.add('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {v:i for v,i in zip(vocab_list, range(0, len(vocab_list)+1))}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 0,\n",
       " 'algorithm': 1,\n",
       " 'maximize': 2,\n",
       " 'machine': 3,\n",
       " 'while': 4,\n",
       " 'can': 5,\n",
       " 'making': 6,\n",
       " 'predictions': 7,\n",
       " 'natural': 8,\n",
       " 'to': 9,\n",
       " 'feedback': 10,\n",
       " 'systems': 11,\n",
       " 'algorithms': 12,\n",
       " 'type': 13,\n",
       " 'artificial': 14,\n",
       " 'such': 15,\n",
       " 'vision': 16,\n",
       " 'penalty': 17,\n",
       " 'intelligence': 18,\n",
       " 'relationships': 19,\n",
       " 'around': 20,\n",
       " 'general': 21,\n",
       " 'as': 22,\n",
       " 'task': 23,\n",
       " 'over': 24,\n",
       " 'main': 25,\n",
       " 'refers': 26,\n",
       " 'processing': 27,\n",
       " 'given': 28,\n",
       " 'perform': 29,\n",
       " 'understand': 30,\n",
       " 'time': 31,\n",
       " 'what': 32,\n",
       " 'neural': 33,\n",
       " 'without': 34,\n",
       " 'answer': 35,\n",
       " 'aims': 36,\n",
       " 'environment': 37,\n",
       " '-': 38,\n",
       " 'have': 39,\n",
       " 'being': 40,\n",
       " 'way': 41,\n",
       " 'analyze': 42,\n",
       " 'many': 43,\n",
       " 'and': 44,\n",
       " 'complex': 45,\n",
       " 'focuses': 46,\n",
       " 'on': 47,\n",
       " 'by': 48,\n",
       " 'consists': 49,\n",
       " 'improve': 50,\n",
       " 'inspired': 51,\n",
       " 'categories': 52,\n",
       " 'us': 53,\n",
       " 'the': 54,\n",
       " 'development': 55,\n",
       " 'ability': 56,\n",
       " 'require': 57,\n",
       " 'make': 58,\n",
       " 'decision': 59,\n",
       " 'interpret': 60,\n",
       " 'computer': 61,\n",
       " '.': 62,\n",
       " 'visual': 63,\n",
       " 'transmit': 64,\n",
       " 'would': 65,\n",
       " 'recognition': 66,\n",
       " 'human': 67,\n",
       " 'receives': 68,\n",
       " 'like': 69,\n",
       " 'patterns': 70,\n",
       " 'subset': 71,\n",
       " 'with': 72,\n",
       " 'narrow': 73,\n",
       " 'network': 74,\n",
       " 'interconnected': 75,\n",
       " 'data': 76,\n",
       " 'enabling': 77,\n",
       " 'takes': 78,\n",
       " 'this': 79,\n",
       " 'signal': 80,\n",
       " 'ai': 81,\n",
       " 'structure': 82,\n",
       " 'its': 83,\n",
       " 'neurons': 84,\n",
       " 'perception': 85,\n",
       " 'networks': 86,\n",
       " 'uses': 87,\n",
       " 'layers': 88,\n",
       " 'various': 89,\n",
       " 'deep': 90,\n",
       " 'examples': 91,\n",
       " 'actions': 92,\n",
       " '?': 93,\n",
       " 'specific': 94,\n",
       " 'typically': 95,\n",
       " 'system': 96,\n",
       " 'in': 97,\n",
       " 'reward': 98,\n",
       " 'unsupervised': 99,\n",
       " 'or': 100,\n",
       " 'take': 101,\n",
       " 'nodes': 102,\n",
       " 'are': 103,\n",
       " ',': 104,\n",
       " 'that': 105,\n",
       " 'process': 106,\n",
       " 'learn': 107,\n",
       " 'reinforcement': 108,\n",
       " 'function': 109,\n",
       " 'allows': 110,\n",
       " 'brain': 111,\n",
       " 'question': 112,\n",
       " ':': 113,\n",
       " 'where': 114,\n",
       " 'language': 115,\n",
       " 'learns': 116,\n",
       " 'from': 117,\n",
       " 'simulate': 118,\n",
       " 'an': 119,\n",
       " 'labeled': 120,\n",
       " 'computers': 121,\n",
       " 'based': 122,\n",
       " 'learning': 123,\n",
       " '<UNK>': 124,\n",
       " 'using': 125,\n",
       " 'computing': 126,\n",
       " 'works': 127,\n",
       " 'is': 128,\n",
       " 'information': 129,\n",
       " 'tasks': 130,\n",
       " 'world': 131,\n",
       " 'form': 132,\n",
       " 'two': 133,\n",
       " 'designed': 134,\n",
       " 'a': 135,\n",
       " 'generate': 136,\n",
       " 'speech': 137,\n",
       " 'decisions': 138,\n",
       " 'it': 139,\n",
       " 'translation': 140}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.randn(len(vocab),embedding_dims)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9709, -0.6108, -0.7059,  0.6737, -0.0704, -0.4620, -0.1340, -2.8420,\n",
       "          1.2939, -1.2586],\n",
       "        [ 2.0123,  1.1058, -1.2964, -0.3664,  1.3379,  0.7395, -0.2012,  0.5657,\n",
       "          0.9096,  1.8883],\n",
       "        [ 1.1060,  2.8013,  0.6866, -0.2444,  0.1662, -1.4238,  0.2097,  0.8396,\n",
       "         -1.5886,  1.3464]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5536, -1.4848, -1.3051,  0.0212, -1.0637,  0.3486, -0.3957,  0.6814,\n",
       "         0.3893,  2.1993])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding(word, vocab=vocab, embedding_matrix=embedding_matrix):\n",
    "    if word not in vocab:\n",
    "        word = '<UNK>'\n",
    "    embedding = embedding_matrix[vocab[word]]\n",
    "    return embedding\n",
    "\n",
    "get_word_embedding('as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_color import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=n, num_hidden_layer=1024, vocab_len = len(vocab_list), dim_embedding=10):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.n = n\n",
    "        self.dim_embedding = dim_embedding\n",
    "        # self.embedding = torch.rand(vocab_len, dim_embedding).to(device)\n",
    "        self.embedding = nn.Embedding(vocab_len, dim_embedding).to(device)\n",
    "\n",
    "        self.hidden_layer = nn.Linear((n-1)*dim_embedding, num_hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(num_hidden_layer, vocab_len)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x will be the indeices of embedding representing the input words\n",
    "        # print(self.embedding(x), color='purple')\n",
    "        x_embeddings = self.embedding(x).view(-1,(self.n-1)*self.dim_embedding).to(device)\n",
    "\n",
    "        out = self.hidden_layer(x_embeddings)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        # out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork(n=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'.lower()\n",
    "    tokenized_data = tokenize(data)\n",
    "    for i in range(len(tokenized_data)-n):\n",
    "        # print(i)\n",
    "        data_i = tokenized_data[i:i+n]\n",
    "        dataset.append([vocab[i] if i in vocab else vocab['<UNK>'] for i in data_i])\n",
    "    # print()\n",
    "\n",
    "dataset_np = np.array(dataset)\n",
    "dataset_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.x = dataset[:,[i for i in range(n-1)]]\n",
    "        self.y = dataset[:,-1]\n",
    "        self.m, self.n = self.x.shape\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.m\n",
    "    \n",
    "dataset = QuestionAnswerDataset(dataset=dataset_np)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCategory = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.949789047241211\u001b[0m\n",
      "4.9633331298828125\u001b[0m\n",
      "4.935501575469971\u001b[0m\n",
      "4.928872108459473\u001b[0m\n",
      "4.910515308380127\u001b[0m\n",
      "4.910934925079346\u001b[0m\n",
      "4.892205238342285\u001b[0m\n",
      "4.883504390716553\u001b[0m\n",
      "4.864453315734863\u001b[0m\n",
      "4.872479438781738\u001b[0m\n",
      "4.85221004486084\u001b[0m\n",
      "4.837987899780273\u001b[0m\n",
      "4.8251423835754395\u001b[0m\n",
      "4.825071334838867\u001b[0m\n",
      "4.798806667327881\u001b[0m\n",
      "4.813121795654297\u001b[0m\n",
      "4.786582946777344\u001b[0m\n",
      "4.778018951416016\u001b[0m\n",
      "4.785912036895752\u001b[0m\n",
      "4.7265753746032715\u001b[0m\n",
      "4.746213436126709\u001b[0m\n",
      "4.734324932098389\u001b[0m\n",
      "4.702948570251465\u001b[0m\n",
      "4.750696182250977\u001b[0m\n",
      "4.71498441696167\u001b[0m\n",
      "4.680456161499023\u001b[0m\n",
      "4.711821556091309\u001b[0m\n",
      "4.635204315185547\u001b[0m\n",
      "4.6762919425964355\u001b[0m\n",
      "4.639272212982178\u001b[0m\n",
      "4.638580322265625\u001b[0m\n",
      "4.648630619049072\u001b[0m\n",
      "4.6040120124816895\u001b[0m\n",
      "4.653141021728516\u001b[0m\n",
      "4.639750957489014\u001b[0m\n",
      "4.549374103546143\u001b[0m\n",
      "4.602304458618164\u001b[0m\n",
      "4.557648181915283\u001b[0m\n",
      "4.560262680053711\u001b[0m\n",
      "4.577327251434326\u001b[0m\n",
      "4.585618019104004\u001b[0m\n",
      "4.489538192749023\u001b[0m\n",
      "4.527306079864502\u001b[0m\n",
      "4.534140110015869\u001b[0m\n",
      "4.5193400382995605\u001b[0m\n",
      "4.500542163848877\u001b[0m\n",
      "4.480415344238281\u001b[0m\n",
      "4.516519546508789\u001b[0m\n",
      "4.461699485778809\u001b[0m\n",
      "4.501625061035156\u001b[0m\n",
      "4.437311172485352\u001b[0m\n",
      "4.496888637542725\u001b[0m\n",
      "4.429672718048096\u001b[0m\n",
      "4.466240882873535\u001b[0m\n",
      "4.421779632568359\u001b[0m\n",
      "4.435142517089844\u001b[0m\n",
      "4.406792640686035\u001b[0m\n",
      "4.416616439819336\u001b[0m\n",
      "4.370521545410156\u001b[0m\n",
      "4.431807041168213\u001b[0m\n",
      "4.398433685302734\u001b[0m\n",
      "4.3468122482299805\u001b[0m\n",
      "4.356692314147949\u001b[0m\n",
      "4.371373176574707\u001b[0m\n",
      "4.3281450271606445\u001b[0m\n",
      "4.375898838043213\u001b[0m\n",
      "4.294524192810059\u001b[0m\n",
      "4.389864444732666\u001b[0m\n",
      "4.343749046325684\u001b[0m\n",
      "4.27293062210083\u001b[0m\n",
      "4.277133941650391\u001b[0m\n",
      "4.338663101196289\u001b[0m\n",
      "4.262148857116699\u001b[0m\n",
      "4.324001789093018\u001b[0m\n",
      "4.285144805908203\u001b[0m\n",
      "4.250862121582031\u001b[0m\n",
      "4.248109817504883\u001b[0m\n",
      "4.271524906158447\u001b[0m\n",
      "4.25973653793335\u001b[0m\n",
      "4.216843128204346\u001b[0m\n",
      "4.221364498138428\u001b[0m\n",
      "4.241563320159912\u001b[0m\n",
      "4.177984714508057\u001b[0m\n",
      "4.2733612060546875\u001b[0m\n",
      "4.249171733856201\u001b[0m\n",
      "4.126156330108643\u001b[0m\n",
      "4.229221820831299\u001b[0m\n",
      "4.1221723556518555\u001b[0m\n",
      "4.2164530754089355\u001b[0m\n",
      "4.107517719268799\u001b[0m\n",
      "4.152841091156006\u001b[0m\n",
      "4.173086166381836\u001b[0m\n",
      "4.174423694610596\u001b[0m\n",
      "4.1056227684021\u001b[0m\n",
      "4.136198997497559\u001b[0m\n",
      "4.132331371307373\u001b[0m\n",
      "4.0825042724609375\u001b[0m\n",
      "4.18351936340332\u001b[0m\n",
      "4.09235954284668\u001b[0m\n",
      "4.136550426483154\u001b[0m\n",
      "4.143420219421387\u001b[0m\n",
      "4.0242695808410645\u001b[0m\n",
      "4.131450653076172\u001b[0m\n",
      "4.011662006378174\u001b[0m\n",
      "4.08574104309082\u001b[0m\n",
      "4.052609443664551\u001b[0m\n",
      "4.0728559494018555\u001b[0m\n",
      "4.041340351104736\u001b[0m\n",
      "4.073422431945801\u001b[0m\n",
      "4.010132789611816\u001b[0m\n",
      "4.0567851066589355\u001b[0m\n",
      "4.006237983703613\u001b[0m\n",
      "4.029780387878418\u001b[0m\n",
      "4.01831579208374\u001b[0m\n",
      "3.973318338394165\u001b[0m\n",
      "4.077946186065674\u001b[0m\n",
      "3.98818302154541\u001b[0m\n",
      "4.026361465454102\u001b[0m\n",
      "3.9688000679016113\u001b[0m\n",
      "4.027886867523193\u001b[0m\n",
      "3.9670557975769043\u001b[0m\n",
      "4.002396583557129\u001b[0m\n",
      "4.0168304443359375\u001b[0m\n",
      "3.8964102268218994\u001b[0m\n",
      "3.973024845123291\u001b[0m\n",
      "3.937285900115967\u001b[0m\n",
      "3.87308931350708\u001b[0m\n",
      "4.067261695861816\u001b[0m\n",
      "3.921571731567383\u001b[0m\n",
      "3.963648796081543\u001b[0m\n",
      "3.907952070236206\u001b[0m\n",
      "3.958311080932617\u001b[0m\n",
      "3.891554355621338\u001b[0m\n",
      "3.958205461502075\u001b[0m\n",
      "3.911162853240967\u001b[0m\n",
      "3.9012386798858643\u001b[0m\n",
      "3.8996317386627197\u001b[0m\n",
      "3.8934824466705322\u001b[0m\n",
      "3.8809263706207275\u001b[0m\n",
      "3.896604537963867\u001b[0m\n",
      "3.8893513679504395\u001b[0m\n",
      "3.858323097229004\u001b[0m\n",
      "3.8536343574523926\u001b[0m\n",
      "3.8892321586608887\u001b[0m\n",
      "3.850921154022217\u001b[0m\n",
      "3.8681890964508057\u001b[0m\n",
      "3.8274054527282715\u001b[0m\n",
      "3.8807530403137207\u001b[0m\n",
      "3.8395721912384033\u001b[0m\n",
      "3.837324857711792\u001b[0m\n",
      "3.808082103729248\u001b[0m\n",
      "3.8628323078155518\u001b[0m\n",
      "3.8335726261138916\u001b[0m\n",
      "3.798597812652588\u001b[0m\n",
      "3.8444502353668213\u001b[0m\n",
      "3.757643938064575\u001b[0m\n",
      "3.8412296772003174\u001b[0m\n",
      "3.7395617961883545\u001b[0m\n",
      "3.8835155963897705\u001b[0m\n",
      "3.649442434310913\u001b[0m\n",
      "3.7565019130706787\u001b[0m\n",
      "3.8252158164978027\u001b[0m\n",
      "3.7772536277770996\u001b[0m\n",
      "3.770524024963379\u001b[0m\n",
      "3.771644353866577\u001b[0m\n",
      "3.7559807300567627\u001b[0m\n",
      "3.770688533782959\u001b[0m\n",
      "3.735619306564331\u001b[0m\n",
      "3.7838361263275146\u001b[0m\n",
      "3.6928913593292236\u001b[0m\n",
      "3.772883415222168\u001b[0m\n",
      "3.687300682067871\u001b[0m\n",
      "3.7684874534606934\u001b[0m\n",
      "3.67193603515625\u001b[0m\n",
      "3.6742701530456543\u001b[0m\n",
      "3.7983357906341553\u001b[0m\n",
      "3.765521287918091\u001b[0m\n",
      "3.6338698863983154\u001b[0m\n",
      "3.788759708404541\u001b[0m\n",
      "3.5759854316711426\u001b[0m\n",
      "3.7590184211730957\u001b[0m\n",
      "3.6011457443237305\u001b[0m\n",
      "3.676548957824707\u001b[0m\n",
      "3.7099485397338867\u001b[0m\n",
      "3.618773937225342\u001b[0m\n",
      "3.779810667037964\u001b[0m\n",
      "3.6485579013824463\u001b[0m\n",
      "3.7130987644195557\u001b[0m\n",
      "3.6270952224731445\u001b[0m\n",
      "3.726184368133545\u001b[0m\n",
      "3.630958318710327\u001b[0m\n",
      "3.6998703479766846\u001b[0m\n",
      "3.641754388809204\u001b[0m\n",
      "3.6634299755096436\u001b[0m\n",
      "3.5842134952545166\u001b[0m\n",
      "3.734248161315918\u001b[0m\n",
      "3.6266212463378906\u001b[0m\n",
      "3.6472346782684326\u001b[0m\n",
      "3.628783702850342\u001b[0m\n",
      "3.6244966983795166\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (input, label) in enumerate(dataloader):\n",
    "        x = input.to(device)\n",
    "        y = label.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = lossCategory(y_pred, y)\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
