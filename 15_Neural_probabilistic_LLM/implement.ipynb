{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "embedding_dims = 10 # how many dimensional vector should represent each word in the vocabulory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "df = ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', '!', '!', '!', 'name', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    data = sentence\n",
    "    split_terms = [',', '.', '!', '?', '(', ')', '&', '$', '+', '-', '/', '*', ';', ':']\n",
    "    for split_term in split_terms:\n",
    "        if split_term in sentence:\n",
    "            data = data.replace(split_term, f' {split_term} ')\n",
    "    data = data.split()\n",
    "    return data\n",
    "\n",
    "tokenize('what is your !! ! name ?    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = set()\n",
    "X = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'\n",
    "    data = data.lower().replace('\\\\n', '')\n",
    "    vocab_list.update(tokenize(data))\n",
    "    X.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list.add('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {v:i for v,i in zip(vocab_list, range(0, len(vocab_list)+1))}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'such': 0,\n",
       " 'typically': 1,\n",
       " 'as': 2,\n",
       " '-': 3,\n",
       " 'us': 4,\n",
       " 'question': 5,\n",
       " 'refers': 6,\n",
       " 'speech': 7,\n",
       " 'and': 8,\n",
       " 'algorithm': 9,\n",
       " 'over': 10,\n",
       " 'its': 11,\n",
       " 'form': 12,\n",
       " 'deep': 13,\n",
       " 'systems': 14,\n",
       " 'labeled': 15,\n",
       " 'tasks': 16,\n",
       " 'receives': 17,\n",
       " 'general': 18,\n",
       " 'make': 19,\n",
       " 'subset': 20,\n",
       " 'based': 21,\n",
       " 'network': 22,\n",
       " 'natural': 23,\n",
       " 'two': 24,\n",
       " 'answer': 25,\n",
       " 'task': 26,\n",
       " 'many': 27,\n",
       " 'perform': 28,\n",
       " 'a': 29,\n",
       " 'computers': 30,\n",
       " 'maximize': 31,\n",
       " 'process': 32,\n",
       " 'ai': 33,\n",
       " 'around': 34,\n",
       " 'while': 35,\n",
       " 'consists': 36,\n",
       " 'feedback': 37,\n",
       " 'human': 38,\n",
       " 'narrow': 39,\n",
       " 'information': 40,\n",
       " '<UNK>': 41,\n",
       " 'data': 42,\n",
       " 'signal': 43,\n",
       " 'what': 44,\n",
       " 'decision': 45,\n",
       " 'interconnected': 46,\n",
       " 'development': 47,\n",
       " 'that': 48,\n",
       " 'is': 49,\n",
       " 'computing': 50,\n",
       " 'it': 51,\n",
       " 'require': 52,\n",
       " 'learns': 53,\n",
       " 'an': 54,\n",
       " 'translation': 55,\n",
       " 'way': 56,\n",
       " 'world': 57,\n",
       " 'without': 58,\n",
       " 'neural': 59,\n",
       " '.': 60,\n",
       " 'on': 61,\n",
       " 'given': 62,\n",
       " 'recognition': 63,\n",
       " 'various': 64,\n",
       " 'vision': 65,\n",
       " 'where': 66,\n",
       " '?': 67,\n",
       " 'by': 68,\n",
       " 'actions': 69,\n",
       " 'relationships': 70,\n",
       " 'nodes': 71,\n",
       " 'specific': 72,\n",
       " 'are': 73,\n",
       " 'perception': 74,\n",
       " 'algorithms': 75,\n",
       " 'processing': 76,\n",
       " 'this': 77,\n",
       " 'layers': 78,\n",
       " 'works': 79,\n",
       " 'generate': 80,\n",
       " 'environment': 81,\n",
       " 'decisions': 82,\n",
       " ':': 83,\n",
       " 'uses': 84,\n",
       " 'intelligence': 85,\n",
       " 'in': 86,\n",
       " 'from': 87,\n",
       " 'main': 88,\n",
       " 'brain': 89,\n",
       " 'designed': 90,\n",
       " 'can': 91,\n",
       " 'like': 92,\n",
       " 'type': 93,\n",
       " 'language': 94,\n",
       " 'visual': 95,\n",
       " 'unsupervised': 96,\n",
       " 'have': 97,\n",
       " 'with': 98,\n",
       " 'networks': 99,\n",
       " 'the': 100,\n",
       " 'examples': 101,\n",
       " 'complex': 102,\n",
       " 'inspired': 103,\n",
       " 'or': 104,\n",
       " 'take': 105,\n",
       " 'patterns': 106,\n",
       " 'ability': 107,\n",
       " 'improve': 108,\n",
       " 'using': 109,\n",
       " 'to': 110,\n",
       " 'being': 111,\n",
       " 'time': 112,\n",
       " 'neurons': 113,\n",
       " ',': 114,\n",
       " 'machine': 115,\n",
       " 'reinforcement': 116,\n",
       " 'penalty': 117,\n",
       " 'would': 118,\n",
       " 'interpret': 119,\n",
       " 'aims': 120,\n",
       " 'simulate': 121,\n",
       " 'categories': 122,\n",
       " 'system': 123,\n",
       " 'learn': 124,\n",
       " 'of': 125,\n",
       " 'learning': 126,\n",
       " 'reward': 127,\n",
       " 'transmit': 128,\n",
       " 'artificial': 129,\n",
       " 'focuses': 130,\n",
       " 'takes': 131,\n",
       " 'making': 132,\n",
       " 'analyze': 133,\n",
       " 'predictions': 134,\n",
       " 'structure': 135,\n",
       " 'computer': 136,\n",
       " 'enabling': 137,\n",
       " 'understand': 138,\n",
       " 'function': 139,\n",
       " 'allows': 140}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.randn(len(vocab),embedding_dims)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4601, -1.0276, -0.7393, -1.4246,  1.2579, -0.0627, -0.6399, -0.6654,\n",
       "          0.8230,  0.0858],\n",
       "        [ 1.1210, -0.1327,  1.7362, -0.8127,  1.5506, -0.7988, -2.0659, -0.1187,\n",
       "         -0.7267, -1.2480],\n",
       "        [ 2.1399, -1.2401, -0.5483,  0.2006, -0.2095,  0.7800, -1.6163, -0.0790,\n",
       "          0.0962, -1.1288]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1210, -0.1327,  1.7362, -0.8127,  1.5506, -0.7988, -2.0659, -0.1187,\n",
       "        -0.7267, -1.2480])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding(word, vocab=vocab, embedding_matrix=embedding_matrix):\n",
    "    if word not in vocab:\n",
    "        word = '<UNK>'\n",
    "    embedding = embedding_matrix[vocab[word]]\n",
    "    return embedding\n",
    "\n",
    "get_word_embedding('as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from print_color import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=n, num_hidden_layer=1024, vocab_len = len(vocab_list), dim_embedding=10):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.n = n\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.embedding = nn.Embedding(vocab_len, dim_embedding).to(device)\n",
    "\n",
    "        self.hidden_layer = nn.Linear((n-1)*dim_embedding, num_hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(num_hidden_layer, vocab_len)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x will be the indices of embedding representing the input words\n",
    "        x_embeddings = self.embedding(x).view(-1,(self.n-1)*self.dim_embedding).to(device)\n",
    "        out = self.hidden_layer(x_embeddings)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork(n=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for x,y in zip(df['Question'], df['Answer']):\n",
    "    data = f'Question: {x} Answer: {y}'.lower()\n",
    "    tokenized_data = tokenize(data)\n",
    "    for i in range(len(tokenized_data)-n):\n",
    "        # print(i)\n",
    "        data_i = tokenized_data[i:i+n]\n",
    "        dataset.append([vocab[i] if i in vocab else vocab['<UNK>'] for i in data_i])\n",
    "    # print()\n",
    "\n",
    "dataset_np = np.array(dataset)\n",
    "dataset_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 129],\n",
       " [49, 129, 85],\n",
       " [129, 85, 67],\n",
       " [85, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 129],\n",
       " [83, 129, 85],\n",
       " [129, 85, 6],\n",
       " [85, 6, 110],\n",
       " [6, 110, 100],\n",
       " [110, 100, 47],\n",
       " [100, 47, 125],\n",
       " [47, 125, 136],\n",
       " [125, 136, 14],\n",
       " [136, 14, 48],\n",
       " [14, 48, 91],\n",
       " [48, 91, 28],\n",
       " [91, 28, 16],\n",
       " [28, 16, 48],\n",
       " [16, 48, 118],\n",
       " [48, 118, 1],\n",
       " [118, 1, 52],\n",
       " [1, 52, 38],\n",
       " [52, 38, 85],\n",
       " [38, 85, 114],\n",
       " [85, 114, 0],\n",
       " [114, 0, 2],\n",
       " [0, 2, 95],\n",
       " [2, 95, 74],\n",
       " [95, 74, 114],\n",
       " [74, 114, 7],\n",
       " [114, 7, 63],\n",
       " [7, 63, 114],\n",
       " [63, 114, 45],\n",
       " [114, 45, 3],\n",
       " [45, 3, 132],\n",
       " [3, 132, 114],\n",
       " [132, 114, 8],\n",
       " [114, 8, 94],\n",
       " [8, 94, 55],\n",
       " [94, 55, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 73],\n",
       " [44, 73, 100],\n",
       " [73, 100, 24],\n",
       " [100, 24, 88],\n",
       " [24, 88, 122],\n",
       " [88, 122, 125],\n",
       " [122, 125, 129],\n",
       " [125, 129, 85],\n",
       " [129, 85, 67],\n",
       " [85, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 100],\n",
       " [83, 100, 24],\n",
       " [100, 24, 88],\n",
       " [24, 88, 122],\n",
       " [88, 122, 125],\n",
       " [122, 125, 129],\n",
       " [125, 129, 85],\n",
       " [129, 85, 73],\n",
       " [85, 73, 39],\n",
       " [73, 39, 33],\n",
       " [39, 33, 8],\n",
       " [33, 8, 18],\n",
       " [8, 18, 33],\n",
       " [18, 33, 60],\n",
       " [33, 60, 39],\n",
       " [60, 39, 33],\n",
       " [39, 33, 130],\n",
       " [33, 130, 61],\n",
       " [130, 61, 29],\n",
       " [61, 29, 72],\n",
       " [29, 72, 26],\n",
       " [72, 26, 114],\n",
       " [26, 114, 35],\n",
       " [114, 35, 18],\n",
       " [35, 18, 33],\n",
       " [18, 33, 120],\n",
       " [33, 120, 110],\n",
       " [120, 110, 97],\n",
       " [110, 97, 38],\n",
       " [97, 38, 3],\n",
       " [38, 3, 92],\n",
       " [3, 92, 85],\n",
       " [92, 85, 8],\n",
       " [85, 8, 100],\n",
       " [8, 100, 107],\n",
       " [100, 107, 110],\n",
       " [107, 110, 124],\n",
       " [110, 124, 8],\n",
       " [124, 8, 28],\n",
       " [8, 28, 64],\n",
       " [28, 64, 16],\n",
       " [64, 16, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 115],\n",
       " [49, 115, 126],\n",
       " [115, 126, 67],\n",
       " [126, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 115],\n",
       " [83, 115, 126],\n",
       " [115, 126, 49],\n",
       " [126, 49, 29],\n",
       " [49, 29, 20],\n",
       " [29, 20, 125],\n",
       " [20, 125, 129],\n",
       " [125, 129, 85],\n",
       " [129, 85, 48],\n",
       " [85, 48, 130],\n",
       " [48, 130, 61],\n",
       " [130, 61, 100],\n",
       " [61, 100, 47],\n",
       " [100, 47, 125],\n",
       " [47, 125, 75],\n",
       " [125, 75, 48],\n",
       " [75, 48, 91],\n",
       " [48, 91, 124],\n",
       " [91, 124, 87],\n",
       " [124, 87, 8],\n",
       " [87, 8, 19],\n",
       " [8, 19, 134],\n",
       " [19, 134, 104],\n",
       " [134, 104, 82],\n",
       " [104, 82, 61],\n",
       " [82, 61, 42],\n",
       " [61, 42, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 13],\n",
       " [49, 13, 126],\n",
       " [13, 126, 67],\n",
       " [126, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 13],\n",
       " [83, 13, 126],\n",
       " [13, 126, 49],\n",
       " [126, 49, 29],\n",
       " [49, 29, 20],\n",
       " [29, 20, 125],\n",
       " [20, 125, 115],\n",
       " [125, 115, 126],\n",
       " [115, 126, 48],\n",
       " [126, 48, 84],\n",
       " [48, 84, 13],\n",
       " [84, 13, 59],\n",
       " [13, 59, 99],\n",
       " [59, 99, 98],\n",
       " [99, 98, 27],\n",
       " [98, 27, 78],\n",
       " [27, 78, 110],\n",
       " [78, 110, 124],\n",
       " [110, 124, 87],\n",
       " [124, 87, 8],\n",
       " [87, 8, 19],\n",
       " [8, 19, 134],\n",
       " [19, 134, 61],\n",
       " [134, 61, 102],\n",
       " [61, 102, 42],\n",
       " [102, 42, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 23],\n",
       " [49, 23, 94],\n",
       " [23, 94, 76],\n",
       " [94, 76, 67],\n",
       " [76, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 23],\n",
       " [83, 23, 94],\n",
       " [23, 94, 76],\n",
       " [94, 76, 49],\n",
       " [76, 49, 29],\n",
       " [49, 29, 20],\n",
       " [29, 20, 125],\n",
       " [20, 125, 129],\n",
       " [125, 129, 85],\n",
       " [129, 85, 48],\n",
       " [85, 48, 130],\n",
       " [48, 130, 61],\n",
       " [130, 61, 137],\n",
       " [61, 137, 30],\n",
       " [137, 30, 110],\n",
       " [30, 110, 138],\n",
       " [110, 138, 114],\n",
       " [138, 114, 119],\n",
       " [114, 119, 114],\n",
       " [119, 114, 8],\n",
       " [114, 8, 80],\n",
       " [8, 80, 38],\n",
       " [80, 38, 94],\n",
       " [38, 94, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 136],\n",
       " [49, 136, 65],\n",
       " [136, 65, 67],\n",
       " [65, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 136],\n",
       " [83, 136, 65],\n",
       " [136, 65, 49],\n",
       " [65, 49, 29],\n",
       " [49, 29, 20],\n",
       " [29, 20, 125],\n",
       " [20, 125, 129],\n",
       " [125, 129, 85],\n",
       " [129, 85, 48],\n",
       " [85, 48, 130],\n",
       " [48, 130, 61],\n",
       " [130, 61, 137],\n",
       " [61, 137, 30],\n",
       " [137, 30, 110],\n",
       " [30, 110, 119],\n",
       " [110, 119, 8],\n",
       " [119, 8, 138],\n",
       " [8, 138, 95],\n",
       " [138, 95, 42],\n",
       " [95, 42, 87],\n",
       " [42, 87, 100],\n",
       " [87, 100, 57],\n",
       " [100, 57, 34],\n",
       " [57, 34, 4],\n",
       " [34, 4, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 54],\n",
       " [49, 54, 129],\n",
       " [54, 129, 59],\n",
       " [129, 59, 22],\n",
       " [59, 22, 67],\n",
       " [22, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 54],\n",
       " [83, 54, 129],\n",
       " [54, 129, 59],\n",
       " [129, 59, 22],\n",
       " [59, 22, 49],\n",
       " [22, 49, 29],\n",
       " [49, 29, 50],\n",
       " [29, 50, 123],\n",
       " [50, 123, 103],\n",
       " [123, 103, 68],\n",
       " [103, 68, 100],\n",
       " [68, 100, 135],\n",
       " [100, 135, 8],\n",
       " [135, 8, 139],\n",
       " [8, 139, 125],\n",
       " [139, 125, 100],\n",
       " [125, 100, 38],\n",
       " [100, 38, 89],\n",
       " [38, 89, 48],\n",
       " [89, 48, 91],\n",
       " [48, 91, 124],\n",
       " [91, 124, 87],\n",
       " [124, 87, 8],\n",
       " [87, 8, 19],\n",
       " [8, 19, 134],\n",
       " [19, 134, 61],\n",
       " [134, 61, 42],\n",
       " [61, 42, 60],\n",
       " [42, 60, 51],\n",
       " [60, 51, 36],\n",
       " [51, 36, 125],\n",
       " [36, 125, 46],\n",
       " [125, 46, 71],\n",
       " [46, 71, 114],\n",
       " [71, 114, 104],\n",
       " [114, 104, 129],\n",
       " [104, 129, 113],\n",
       " [129, 113, 114],\n",
       " [113, 114, 48],\n",
       " [114, 48, 32],\n",
       " [48, 32, 8],\n",
       " [32, 8, 128],\n",
       " [8, 128, 40],\n",
       " [128, 40, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 116],\n",
       " [49, 116, 126],\n",
       " [116, 126, 67],\n",
       " [126, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 116],\n",
       " [83, 116, 126],\n",
       " [116, 126, 49],\n",
       " [126, 49, 29],\n",
       " [49, 29, 20],\n",
       " [29, 20, 125],\n",
       " [20, 125, 115],\n",
       " [125, 115, 126],\n",
       " [115, 126, 66],\n",
       " [126, 66, 54],\n",
       " [66, 54, 9],\n",
       " [54, 9, 53],\n",
       " [9, 53, 110],\n",
       " [53, 110, 105],\n",
       " [110, 105, 69],\n",
       " [105, 69, 86],\n",
       " [69, 86, 54],\n",
       " [86, 54, 81],\n",
       " [54, 81, 110],\n",
       " [81, 110, 31],\n",
       " [110, 31, 29],\n",
       " [31, 29, 127],\n",
       " [29, 127, 43],\n",
       " [127, 43, 60],\n",
       " [43, 60, 100],\n",
       " [60, 100, 9],\n",
       " [100, 9, 17],\n",
       " [9, 17, 37],\n",
       " [17, 37, 86],\n",
       " [37, 86, 100],\n",
       " [86, 100, 12],\n",
       " [100, 12, 125],\n",
       " [12, 125, 29],\n",
       " [125, 29, 127],\n",
       " [29, 127, 104],\n",
       " [127, 104, 117],\n",
       " [104, 117, 21],\n",
       " [117, 21, 61],\n",
       " [21, 61, 100],\n",
       " [61, 100, 69],\n",
       " [100, 69, 51],\n",
       " [69, 51, 131],\n",
       " [51, 131, 114],\n",
       " [131, 114, 8],\n",
       " [114, 8, 84],\n",
       " [8, 84, 77],\n",
       " [84, 77, 37],\n",
       " [77, 37, 110],\n",
       " [37, 110, 108],\n",
       " [110, 108, 11],\n",
       " [108, 11, 45],\n",
       " [11, 45, 3],\n",
       " [45, 3, 132],\n",
       " [3, 132, 10],\n",
       " [132, 10, 112],\n",
       " [10, 112, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 54],\n",
       " [49, 54, 129],\n",
       " [54, 129, 59],\n",
       " [129, 59, 22],\n",
       " [59, 22, 67],\n",
       " [22, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 54],\n",
       " [83, 54, 129],\n",
       " [54, 129, 59],\n",
       " [129, 59, 22],\n",
       " [59, 22, 49],\n",
       " [22, 49, 29],\n",
       " [49, 29, 93],\n",
       " [29, 93, 125],\n",
       " [93, 125, 115],\n",
       " [125, 115, 126],\n",
       " [115, 126, 9],\n",
       " [126, 9, 48],\n",
       " [9, 48, 49],\n",
       " [48, 49, 90],\n",
       " [49, 90, 110],\n",
       " [90, 110, 121],\n",
       " [110, 121, 100],\n",
       " [121, 100, 56],\n",
       " [100, 56, 100],\n",
       " [56, 100, 38],\n",
       " [100, 38, 89],\n",
       " [38, 89, 79],\n",
       " [89, 79, 68],\n",
       " [79, 68, 109],\n",
       " [68, 109, 46],\n",
       " [109, 46, 71],\n",
       " [46, 71, 110],\n",
       " [71, 110, 32],\n",
       " [110, 32, 8],\n",
       " [32, 8, 133],\n",
       " [8, 133, 42],\n",
       " [133, 42, 60],\n",
       " [5, 83, 44],\n",
       " [83, 44, 49],\n",
       " [44, 49, 96],\n",
       " [49, 96, 126],\n",
       " [96, 126, 67],\n",
       " [126, 67, 25],\n",
       " [67, 25, 83],\n",
       " [25, 83, 96],\n",
       " [83, 96, 126],\n",
       " [96, 126, 49],\n",
       " [126, 49, 29],\n",
       " [49, 29, 93],\n",
       " [29, 93, 125],\n",
       " [93, 125, 115],\n",
       " [125, 115, 126],\n",
       " [115, 126, 48],\n",
       " [126, 48, 140],\n",
       " [48, 140, 30],\n",
       " [140, 30, 110],\n",
       " [30, 110, 124],\n",
       " [110, 124, 106],\n",
       " [124, 106, 8],\n",
       " [106, 8, 70],\n",
       " [8, 70, 86],\n",
       " [70, 86, 42],\n",
       " [86, 42, 58],\n",
       " [42, 58, 111],\n",
       " [58, 111, 62],\n",
       " [111, 62, 72],\n",
       " [62, 72, 101],\n",
       " [72, 101, 104],\n",
       " [101, 104, 15],\n",
       " [104, 15, 42],\n",
       " [15, 42, 60]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.x = dataset[:,[i for i in range(n-1)]]\n",
    "        self.y = dataset[:,-1]\n",
    "        self.m, self.n = self.x.shape\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.m\n",
    "    \n",
    "dataset = QuestionAnswerDataset(dataset=dataset_np)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCategory = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/Desktop/AI_ENV/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.981821060180664\u001b[0m\n",
      "4.734204292297363\u001b[0m\n",
      "4.493097305297852\u001b[0m\n",
      "4.2728271484375\u001b[0m\n",
      "4.112992286682129\u001b[0m\n",
      "3.974346160888672\u001b[0m\n",
      "3.8212594985961914\u001b[0m\n",
      "3.779200553894043\u001b[0m\n",
      "3.601888418197632\u001b[0m\n",
      "3.5059938430786133\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (input, label) in enumerate(dataloader):\n",
    "        x = input.to(device)\n",
    "        y = label.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = lossCategory(y_pred, y)\n",
    "        if epoch%10==0 and i==0: \n",
    "            # print(epoch)\n",
    "            print(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 49, 77, 67], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'What is this?'\n",
    "tokenized_text = tokenize(text.lower())\n",
    "embedding_indices = torch.tensor(np.array([vocab[word] for word in tokenized_text])).to(device)\n",
    "embedding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 49, 77, 67], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4498e-01, -7.1713e-01, -4.2650e-01,  4.3660e-01, -2.8130e-01,\n",
       "         -1.2373e+00, -3.9052e-01, -4.0208e-01,  1.9653e-01,  6.2154e-01,\n",
       "         -6.2180e-01, -1.4936e-01, -5.1768e-01,  7.0551e-01, -3.2258e-01,\n",
       "         -4.7212e-01, -1.3177e-01, -5.7923e-01, -3.6617e-01, -2.7128e-01,\n",
       "          7.0688e-02, -5.3920e-01,  5.7039e-01,  3.0758e-01, -1.4865e-01,\n",
       "          5.4150e-01, -5.4369e-01, -1.3179e-01, -5.0321e-01,  3.1005e+00,\n",
       "          5.0916e-02, -3.7448e-01, -3.5911e-03, -1.8104e-01, -6.0373e-01,\n",
       "         -2.1384e-01, -5.1528e-01,  4.8394e-02,  6.1310e-01, -3.3543e-01,\n",
       "         -7.0480e-02, -4.2851e-01,  9.7074e-01, -3.4443e-01, -1.9998e-01,\n",
       "         -1.5703e-01, -3.3473e-01,  2.5693e-01,  1.5371e+00,  1.9967e+00,\n",
       "         -4.3060e-01, -5.8848e-01, -4.9204e-01,  2.6934e-02,  1.8756e+00,\n",
       "         -5.3164e-01, -2.8458e-01, -4.4690e-01, -4.1385e-01,  3.2349e-01,\n",
       "          1.3680e+00,  5.8576e-01, -5.1179e-01, -4.8101e-01, -2.5816e-01,\n",
       "         -3.6412e-01, -1.1374e-01,  1.7420e+00, -2.7452e-01, -9.4523e-02,\n",
       "         -3.4111e-01, -3.2023e-01, -4.0864e-01, -2.8942e-01, -3.0674e-01,\n",
       "         -2.1056e-01, -3.0741e-01, -5.9747e-01, -1.5191e-01, -1.6476e-01,\n",
       "         -6.9191e-01, -4.3563e-01, -3.0177e-01,  1.9121e+00,  2.1375e-02,\n",
       "          5.1518e-01,  4.1429e-02, -1.7541e-01, -4.9443e-01, -3.2885e-01,\n",
       "         -5.0372e-01, -1.3913e-01, -3.6120e-01, -2.6575e-01,  3.3854e-01,\n",
       "         -6.1725e-01,  5.6287e-01, -5.7036e-01, -5.4618e-01, -3.4914e-01,\n",
       "          2.6273e+00, -6.7900e-01, -5.3745e-01, -2.0764e-01,  3.5462e-01,\n",
       "         -6.6915e-01, -9.9123e-01, -3.3585e-01, -1.3514e-01, -2.7292e-01,\n",
       "          1.3342e+00,  2.6547e-02, -3.3095e-01, -5.9595e-01,  8.0400e-01,\n",
       "          1.5363e+00,  6.9795e-02, -3.7921e-01, -5.1920e-01, -9.4948e-02,\n",
       "         -4.4379e-01, -2.4608e-01, -3.8163e-01, -6.5747e-01,  6.7790e-01,\n",
       "          1.5024e+00,  1.6240e+00,  2.6898e-01, -8.5372e-01,  2.2310e+00,\n",
       "          2.8357e-03, -7.1237e-01, -1.4566e-01, -1.9839e-01,  2.2817e-01,\n",
       "         -4.5848e-01,  6.6476e-01, -3.3740e-01,  3.4680e-01, -2.6945e-01,\n",
       "         -4.0045e-01],\n",
       "        [-9.1771e-01, -3.5697e-01,  1.0115e-01,  3.1498e-01, -4.8510e-01,\n",
       "         -9.4634e-01, -1.5682e-01, -4.9380e-01,  2.2429e+00, -4.0809e-01,\n",
       "         -4.7595e-01, -3.8732e-01, -4.1344e-01,  5.6762e-02,  1.6700e-01,\n",
       "         -6.7726e-01, -7.2950e-01, -2.2750e-01, -3.2194e-01, -1.2957e-01,\n",
       "          9.3509e-01, -2.4517e-01,  3.6288e-01, -1.5939e-01, -8.7436e-02,\n",
       "          3.7493e+00, -6.2370e-01, -6.4542e-01,  1.4059e-01,  8.9329e-01,\n",
       "         -1.4817e-01, -2.7012e-01,  6.9329e-02,  3.2641e-01, -6.2276e-01,\n",
       "         -4.0208e-01, -4.6498e-01,  2.6075e-01,  9.8814e-01, -3.3310e-01,\n",
       "         -7.8416e-01, -8.5994e-01,  5.8187e-01, -4.7335e-01, -2.2690e-01,\n",
       "         -1.3036e-01, -3.7298e-01, -1.1240e-01,  2.1047e+00,  1.2613e+00,\n",
       "         -3.1745e-01,  1.0976e-02, -2.9458e-01, -2.1677e-01,  3.6550e-01,\n",
       "         -4.0285e-01, -3.4723e-01, -6.5860e-01, -4.6479e-01,  1.4552e+00,\n",
       "          1.8310e+00,  8.8764e-01, -3.4226e-01, -4.8355e-01, -5.4914e-01,\n",
       "         -1.0092e-01, -6.0953e-01,  1.2918e+00, -1.2001e-01,  2.5346e-01,\n",
       "          3.4536e-02, -6.5461e-01, -6.3918e-01,  2.1453e-02, -3.5038e-01,\n",
       "         -6.2504e-01, -8.9657e-02, -3.6038e-01, -4.8757e-01, -7.4193e-01,\n",
       "         -3.2075e-02, -8.8158e-01, -4.0204e-01,  1.8451e+00, -4.6951e-01,\n",
       "          1.8176e+00,  5.4363e-02, -4.3447e-02, -2.6508e-01, -5.6332e-01,\n",
       "         -5.8472e-01, -1.3079e-01, -1.0329e+00, -1.8394e-01,  3.3694e-01,\n",
       "         -9.2050e-01, -7.8956e-01, -7.4184e-02, -5.7972e-01, -7.7907e-01,\n",
       "          1.3260e+00, -3.5151e-01, -3.3774e-01, -3.1468e-02,  4.8875e-01,\n",
       "         -3.0454e-01, -5.8519e-01, -4.8976e-01, -2.7012e-01, -5.1611e-01,\n",
       "          2.5439e+00, -8.0391e-01, -4.5809e-01, -4.3317e-01,  1.8609e+00,\n",
       "          4.3904e-01, -1.1501e-01, -9.4764e-01, -2.6455e-01,  1.8672e-01,\n",
       "         -7.3352e-01, -3.7948e-01,  1.9805e-01, -7.4206e-01,  5.5802e-01,\n",
       "          1.1984e+00,  1.8372e+00, -6.5879e-02, -2.9358e-01,  9.4864e-01,\n",
       "         -3.2330e-01, -8.1456e-02, -6.6957e-01, -1.9859e-01, -5.0543e-01,\n",
       "         -3.2086e-01,  6.2531e-02, -1.2338e-01, -3.1930e-01, -5.4307e-01,\n",
       "         -6.1238e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(embedding_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(141, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# normalisation, standardise, proper init, weight decay, hyperparameter tunign, diff optimiser test, inference, earlyy stopping\n",
    "# add direct connections, see if it is useful\n",
    "# plot unigram, bi, tri, etc perplexity score, word error rate, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
